# LLM API Keys
GROQ_API_KEY="your-groq-api-key"
OPENAI_API_KEY="your-openai-api-key"
ANTHROPIC_API_KEY="your-anthropic-api-key"
TAVILY_API_KEY="your-tavily-api-key"

# Model Configuration
DEFAULT_MODEL="llama-3.1-70b-versatile"  # Options: llama-3.1-70b-versatile, gpt-4o, gpt-4o-mini, claude-3-5-sonnet-latest, claude-3-5-haiku-latest

# Environment Configuration
ENVIRONMENT="development"  # Options: development, production
LOG_LEVEL="INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Streamlit Configuration
STREAMLIT_THEME="light"  # Options: light, dark
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS="localhost"

# Cache Configuration
CACHE_DIR=".cache"
CACHE_TTL=3600  # Time in seconds

# Visualization Settings
MAX_TREE_DEPTH=5
MAX_NODES_DISPLAY=100
CONFIDENCE_THRESHOLD=0.7

# Debug Settings (Development Only)
DEBUG_MODE=false
VERBOSE_LOGGING=false
PROFILE_PERFORMANCE=false
